{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from link.src.py_scripts.process_pals import begin_processing\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-28 10:31:49,337 - process_pals.py - INFO - Got 3029 files\n",
      "2019-02-28 10:31:51,074 - process_pals.py - INFO - Got 3029 lines\n",
      "2019-02-28 10:31:51,079 - process_pals.py - INFO - Processing with chunk_size = 379. Starting 8 workers\n",
      "2019-02-28 10:31:51,206 - link.src.py_scripts.process_line-9992 - INFO - Started new worker\n",
      "2019-02-28 10:31:51,206 - link.src.py_scripts.process_line-9991 - INFO - Started new worker\n",
      "2019-02-28 10:31:51,209 - link.src.py_scripts.process_line-9993 - INFO - Started new worker\n",
      "2019-02-28 10:31:51,214 - link.src.py_scripts.process_line-9994 - INFO - Started new worker\n",
      "2019-02-28 10:31:51,211 - link.src.py_scripts.process_line-9995 - INFO - Started new worker\n",
      "2019-02-28 10:31:51,216 - link.src.py_scripts.process_line-9996 - INFO - Started new worker\n",
      "2019-02-28 10:31:51,216 - link.src.py_scripts.process_line-9998 - INFO - Started new worker\n",
      "2019-02-28 10:31:51,217 - link.src.py_scripts.process_line-9997 - INFO - Started new worker\n",
      "2019-02-28 10:32:03,316 - link.src.py_scripts.process_line-9995 - INFO - Job finished, execution time 12.84 seconds\n",
      "2019-02-28 10:32:03,419 - link.src.py_scripts.process_line-9991 - INFO - Job finished, execution time 12.18 seconds\n",
      "2019-02-28 10:32:03,609 - link.src.py_scripts.process_line-9994 - INFO - Job finished, execution time 12.38 seconds\n",
      "2019-02-28 10:32:03,803 - link.src.py_scripts.process_line-9997 - INFO - Job finished, execution time 12.55 seconds\n",
      "2019-02-28 10:32:03,862 - link.src.py_scripts.process_line-9993 - INFO - Job finished, execution time 12.63 seconds\n",
      "2019-02-28 10:32:03,991 - link.src.py_scripts.process_line-9992 - INFO - Job finished, execution time 12.75 seconds\n",
      "2019-02-28 10:32:03,974 - link.src.py_scripts.process_line-9998 - INFO - Job finished, execution time 12.74 seconds\n",
      "2019-02-28 10:32:03,992 - link.src.py_scripts.process_line-9996 - INFO - Job finished, execution time 12.73 seconds\n",
      "2019-02-28 10:32:04,245 - process_pals.py - INFO - Combining results into single dict\n",
      "2019-02-28 10:32:04,246 - process_pals.py - INFO - Creating df\n",
      "2019-02-28 10:32:04,669 - process_pals.py - INFO - Writing df to Pseudogenes3End.csv\n",
      "2019-02-28 10:32:05,799 - process_pals.py - INFO - Done! Execution time 16.47 seconds\n"
     ]
    }
   ],
   "source": [
    "# Pseudogenes\n",
    "\n",
    "PATH = '../../data/pseudogenes/50_last_pals/'\n",
    "LINES = 'last'\n",
    "OMIT = ''\n",
    "OUTPUT_FILE = 'Pseudogenes3End.csv'\n",
    "N_LINES = 0\n",
    "\n",
    "_ = begin_processing(\n",
    "    PATH,\n",
    "    LINES,\n",
    "    OMIT,\n",
    "    output_file=OUTPUT_FILE,\n",
    "    n_lines=N_LINES,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-28 10:32:10,160 - process_pals.py - INFO - Got 6245 files\n",
      "2019-02-28 10:32:13,284 - process_pals.py - INFO - Got 6245 lines\n",
      "2019-02-28 10:32:13,285 - process_pals.py - INFO - Processing with chunk_size = 781. Starting 8 workers\n",
      "2019-02-28 10:32:13,411 - link.src.py_scripts.process_line-10066 - INFO - Started new worker\n",
      "2019-02-28 10:32:13,421 - link.src.py_scripts.process_line-10068 - INFO - Started new worker\n",
      "2019-02-28 10:32:13,416 - link.src.py_scripts.process_line-10067 - INFO - Started new worker\n",
      "2019-02-28 10:32:13,424 - link.src.py_scripts.process_line-10070 - INFO - Started new worker\n",
      "2019-02-28 10:32:13,421 - link.src.py_scripts.process_line-10065 - INFO - Started new worker\n",
      "2019-02-28 10:32:13,432 - link.src.py_scripts.process_line-10071 - INFO - Started new worker\n",
      "2019-02-28 10:32:13,422 - link.src.py_scripts.process_line-10069 - INFO - Started new worker\n",
      "2019-02-28 10:32:13,433 - link.src.py_scripts.process_line-10072 - INFO - Started new worker\n",
      "2019-02-28 10:32:35,955 - link.src.py_scripts.process_line-10071 - INFO - Job finished, execution time 22.47 seconds\n",
      "2019-02-28 10:32:36,279 - link.src.py_scripts.process_line-10067 - INFO - Job finished, execution time 22.83 seconds\n",
      "2019-02-28 10:32:36,462 - link.src.py_scripts.process_line-10069 - INFO - Job finished, execution time 23.66 seconds\n",
      "2019-02-28 10:32:36,602 - link.src.py_scripts.process_line-10065 - INFO - Job finished, execution time 23.15 seconds\n",
      "2019-02-28 10:32:36,643 - link.src.py_scripts.process_line-10066 - INFO - Job finished, execution time 23.21 seconds\n",
      "2019-02-28 10:32:36,750 - link.src.py_scripts.process_line-10070 - INFO - Job finished, execution time 23.31 seconds\n",
      "2019-02-28 10:32:37,147 - link.src.py_scripts.process_line-10068 - INFO - Job finished, execution time 23.71 seconds\n",
      "2019-02-28 10:32:37,204 - link.src.py_scripts.process_line-10072 - INFO - Job finished, execution time 23.74 seconds\n",
      "2019-02-28 10:32:37,437 - process_pals.py - INFO - Combining results into single dict\n",
      "2019-02-28 10:32:37,438 - process_pals.py - INFO - Creating df\n",
      "2019-02-28 10:32:38,373 - process_pals.py - INFO - Writing df to Shuffled_Pseudogenes3End.csv\n",
      "2019-02-28 10:32:40,527 - process_pals.py - INFO - Done! Execution time 30.41 seconds\n"
     ]
    }
   ],
   "source": [
    "# Shuffled pseudogenes\n",
    "\n",
    "PATH = '../../data/pseudogenes/50_last_shuffled_pals/'\n",
    "LINES = 'last'\n",
    "OMIT = ''\n",
    "OUTPUT_FILE = 'Shuffled_Pseudogenes3End.csv'\n",
    "N_LINES = 0\n",
    "_ = begin_processing(\n",
    "    PATH,\n",
    "    LINES,\n",
    "    OMIT,\n",
    "    output_file=OUTPUT_FILE,\n",
    "    n_lines=N_LINES,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-25 09:55:52,859 - process_pals.py - INFO - Got 51449 files\n",
      "2019-02-25 09:58:04,998 - process_pals.py - INFO - Got 51449 lines\n",
      "2019-02-25 09:58:04,999 - process_pals.py - INFO - Processing with chunk_size = 6432. Starting 8 workers\n",
      "2019-02-25 09:58:05,043 - link.src.py_scripts.process_line-3282 - INFO - Started new worker\n",
      "2019-02-25 09:58:05,044 - link.src.py_scripts.process_line-3283 - INFO - Started new worker\n",
      "2019-02-25 09:58:05,046 - link.src.py_scripts.process_line-3284 - INFO - Started new worker\n",
      "2019-02-25 09:58:05,048 - link.src.py_scripts.process_line-3285 - INFO - Started new worker\n",
      "2019-02-25 09:58:05,053 - link.src.py_scripts.process_line-3286 - INFO - Started new worker\n",
      "2019-02-25 09:58:05,054 - link.src.py_scripts.process_line-3287 - INFO - Started new worker\n",
      "2019-02-25 09:58:05,056 - link.src.py_scripts.process_line-3288 - INFO - Started new worker\n",
      "2019-02-25 09:58:05,063 - link.src.py_scripts.process_line-3289 - INFO - Started new worker\n",
      "2019-02-25 09:59:21,706 - link.src.py_scripts.process_line-3282 - INFO - Job finished, execution time 76.66 seconds\n",
      "2019-02-25 09:59:21,814 - link.src.py_scripts.process_line-3283 - INFO - Job finished, execution time 76.76 seconds\n",
      "2019-02-25 09:59:21,940 - link.src.py_scripts.process_line-3288 - INFO - Job finished, execution time 76.88 seconds\n",
      "2019-02-25 09:59:22,063 - link.src.py_scripts.process_line-3287 - INFO - Job finished, execution time 76.99 seconds\n",
      "2019-02-25 09:59:22,069 - link.src.py_scripts.process_line-3285 - INFO - Job finished, execution time 77.18 seconds\n",
      "2019-02-25 09:59:22,166 - link.src.py_scripts.process_line-3289 - INFO - Job finished, execution time 77.98 seconds\n",
      "2019-02-25 09:59:22,308 - link.src.py_scripts.process_line-3284 - INFO - Job finished, execution time 77.25 seconds\n",
      "2019-02-25 09:59:22,329 - link.src.py_scripts.process_line-3286 - INFO - Job finished, execution time 77.26 seconds\n",
      "2019-02-25 09:59:23,448 - process_pals.py - INFO - Combining results into single dict\n",
      "2019-02-25 09:59:23,451 - process_pals.py - INFO - Creating df\n",
      "2019-02-25 09:59:25,650 - process_pals.py - INFO - Writing df to KnownGene3End.csv\n",
      "2019-02-25 09:59:33,223 - process_pals.py - INFO - Done! Execution time 220.42 seconds\n"
     ]
    }
   ],
   "source": [
    "# KnownGene\n",
    "\n",
    "PATH = '../../data/knownGene/50_last_pals/'\n",
    "LINES = 'last'\n",
    "OMIT = ''\n",
    "OUTPUT_FILE = 'KnownGene3End.csv'\n",
    "N_LINES = 0\n",
    "\n",
    "_ = begin_processing(\n",
    "    PATH,\n",
    "    LINES,\n",
    "    OMIT,\n",
    "    output_file=OUTPUT_FILE,\n",
    "    n_lines=N_LINES,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-25 09:59:34,267 - process_pals.py - INFO - Got 48792 files\n",
      "2019-02-25 10:05:17,126 - process_pals.py - INFO - Got 48792 lines\n",
      "2019-02-25 10:05:17,126 - process_pals.py - INFO - Processing with chunk_size = 6100. Starting 8 workers\n",
      "2019-02-25 10:05:17,193 - link.src.py_scripts.process_line-3556 - INFO - Started new worker\n",
      "2019-02-25 10:05:17,195 - link.src.py_scripts.process_line-3557 - INFO - Started new worker\n",
      "2019-02-25 10:05:17,208 - link.src.py_scripts.process_line-3559 - INFO - Started new worker\n",
      "2019-02-25 10:05:17,225 - link.src.py_scripts.process_line-3562 - INFO - Started new worker\n",
      "2019-02-25 10:05:17,202 - link.src.py_scripts.process_line-3558 - INFO - Started new worker\n",
      "2019-02-25 10:05:17,219 - link.src.py_scripts.process_line-3561 - INFO - Started new worker\n",
      "2019-02-25 10:05:17,234 - link.src.py_scripts.process_line-3563 - INFO - Started new worker\n",
      "2019-02-25 10:05:17,213 - link.src.py_scripts.process_line-3560 - INFO - Started new worker\n",
      "2019-02-25 10:07:09,659 - link.src.py_scripts.process_line-3562 - INFO - Job finished, execution time 112.42 seconds\n",
      "2019-02-25 10:07:11,425 - link.src.py_scripts.process_line-3558 - INFO - Job finished, execution time 114.19 seconds\n",
      "2019-02-25 10:07:13,280 - link.src.py_scripts.process_line-3559 - INFO - Job finished, execution time 116.56 seconds\n",
      "2019-02-25 10:07:13,302 - link.src.py_scripts.process_line-3561 - INFO - Job finished, execution time 116.66 seconds\n",
      "2019-02-25 10:07:14,135 - link.src.py_scripts.process_line-3556 - INFO - Job finished, execution time 116.93 seconds\n",
      "2019-02-25 10:07:14,173 - link.src.py_scripts.process_line-3557 - INFO - Job finished, execution time 116.97 seconds\n",
      "2019-02-25 10:07:14,226 - link.src.py_scripts.process_line-3560 - INFO - Job finished, execution time 116.97 seconds\n",
      "2019-02-25 10:07:15,140 - link.src.py_scripts.process_line-3563 - INFO - Job finished, execution time 117.89 seconds\n",
      "2019-02-25 10:07:15,847 - process_pals.py - INFO - Combining results into single dict\n",
      "2019-02-25 10:07:15,849 - process_pals.py - INFO - Creating df\n",
      "2019-02-25 10:07:19,841 - process_pals.py - INFO - Writing df to Shuffled_knownGene3End.csv\n",
      "2019-02-25 10:07:31,957 - process_pals.py - INFO - Done! Execution time 478.56 seconds\n"
     ]
    }
   ],
   "source": [
    "# Shuffled knownGene\n",
    "\n",
    "PATH = '../../data/knownGene/50_last_shuffled_pals/'\n",
    "LINES = 'last'\n",
    "OMIT = ''\n",
    "OUTPUT_FILE = 'Shuffled_knownGene3End.csv'\n",
    "N_LINES = 0\n",
    "\n",
    "_ = begin_processing(\n",
    "    PATH,\n",
    "    LINES,\n",
    "    OMIT,\n",
    "    output_file=OUTPUT_FILE,\n",
    "    n_lines=N_LINES,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database',)).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "# 50 last bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_path = '../../data/L1/data/50_last/'\n",
    "l1_files = os.listdir(l1_path)\n",
    "sequences = []\n",
    "for f_n in l1_files:\n",
    "    with open(os.path.join(l1_path, f_n), 'r') as file:\n",
    "        sequences.append(file.readlines()[1].strip().upper())\n",
    "# sequences = np.unique(sequences)\n",
    "\n",
    "with open('L1_50_last.txt', 'w') as file:\n",
    "    for seq in sequences:\n",
    "        file.write(seq)\n",
    "        file.write('\\n')\n",
    "\n",
    "\n",
    "l1_shuffled_path = '../../data/L1/data/shuffled_50_last/'\n",
    "l1_shuffled_files = os.listdir(l1_shuffled_path)\n",
    "sequences = []\n",
    "for f_n in l1_shuffled_files:\n",
    "    with open(os.path.join(l1_shuffled_path, f_n), 'r') as file:\n",
    "        sequences.append(file.readlines()[0].strip().upper())\n",
    "sequences = np.unique(sequences)\n",
    "\n",
    "with open('L1_50_last_shuffled.txt', 'w') as file:\n",
    "    for seq in sequences:\n",
    "        file.write(seq)\n",
    "        file.write('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "knownGene_path = '../../data/knownGene/50_last/'\n",
    "knownGene_files = os.listdir(knownGene_path)\n",
    "sequences = []\n",
    "for f_n in knownGene_files:\n",
    "    with open(os.path.join(knownGene_path, f_n), 'r') as file:\n",
    "        sequences.append(file.readlines()[1].strip().upper())\n",
    "sequences = np.unique(sequences)\n",
    "\n",
    "with open('KnownGene_50_last.txt', 'w') as file:\n",
    "    for seq in sequences:\n",
    "        file.write(seq)\n",
    "        file.write('\\n')\n",
    "\n",
    "knownGene_shuffled_path = '../../data/knownGene/50_last_shuffled/'\n",
    "knownGene_shuffled_files = os.listdir(knownGene_shuffled_path)\n",
    "sequences = []\n",
    "for f_n in knownGene_shuffled_files:\n",
    "    with open(os.path.join(knownGene_shuffled_path, f_n), 'r') as file:\n",
    "        sequences.append(file.readlines()[0].strip().upper())\n",
    "sequences = np.unique(sequences)\n",
    "\n",
    "with open('KnownGene_50_last_shuffled.txt', 'w') as file:\n",
    "    for seq in sequences:\n",
    "        file.write(seq)\n",
    "        file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudogenes_path = '../../data/pseudogenes/50_last/'\n",
    "pseudogenes_files = os.listdir(pseudogenes_path)\n",
    "sequences = []\n",
    "for f_n in pseudogenes_files:\n",
    "    with open(os.path.join(pseudogenes_path, f_n), 'r') as file:\n",
    "        sequences.append(file.readlines()[1].strip().upper())\n",
    "sequences = np.unique(sequences)\n",
    "\n",
    "with open('pseudogenes_50_last.txt', 'w') as file:\n",
    "    for seq in sequences:\n",
    "        file.write(seq)\n",
    "        file.write('\\n')\n",
    "\n",
    "pseudogenes_shuffled_path = '../../data/pseudogenes/50_last_shuffled/'\n",
    "pseudogenes_shuffled_files = os.listdir(pseudogenes_shuffled_path)\n",
    "sequences = []\n",
    "for f_n in pseudogenes_shuffled_files:\n",
    "    with open(os.path.join(pseudogenes_shuffled_path, f_n), 'r') as file:\n",
    "        sequences.append(file.readlines()[0].strip().upper())\n",
    "sequences = np.unique(sequences)\n",
    "\n",
    "with open('pseudogenes_50_last_shuffled.txt', 'w') as file:\n",
    "    for seq in sequences:\n",
    "        file.write(seq)\n",
    "        file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-06 18:09:42,743 - process_pals.py - INFO - Got 191 files\n",
      "2019-04-06 18:09:42,864 - process_pals.py - INFO - Got 191 lines\n",
      "2019-04-06 18:09:42,864 - process_pals.py - INFO - Processing with chunk_size = 24. Starting 8 workers\n",
      "2019-04-06 18:09:42,918 - link.src.py_scripts.process_line-9394 - INFO - Started new worker\n",
      "2019-04-06 18:09:42,918 - link.src.py_scripts.process_line-9395 - INFO - Started new worker\n",
      "2019-04-06 18:09:42,918 - link.src.py_scripts.process_line-9398 - INFO - Started new worker\n",
      "2019-04-06 18:09:42,918 - link.src.py_scripts.process_line-9399 - INFO - Started new worker\n",
      "2019-04-06 18:09:42,918 - link.src.py_scripts.process_line-9396 - INFO - Started new worker\n",
      "2019-04-06 18:09:42,919 - link.src.py_scripts.process_line-9397 - INFO - Started new worker\n",
      "2019-04-06 18:09:42,917 - link.src.py_scripts.process_line-9393 - INFO - Started new worker\n",
      "2019-04-06 18:09:42,917 - link.src.py_scripts.process_line-9392 - INFO - Started new worker\n",
      "2019-04-06 18:09:43,367 - link.src.py_scripts.process_line-9392 - INFO - Job finished, execution time 0.44 seconds\n",
      "2019-04-06 18:09:43,369 - link.src.py_scripts.process_line-9393 - INFO - Job finished, execution time 0.44 seconds\n",
      "2019-04-06 18:09:43,367 - link.src.py_scripts.process_line-9395 - INFO - Job finished, execution time 0.44 seconds\n",
      "2019-04-06 18:09:43,371 - link.src.py_scripts.process_line-9397 - INFO - Job finished, execution time 0.44 seconds\n",
      "2019-04-06 18:09:43,389 - link.src.py_scripts.process_line-9398 - INFO - Job finished, execution time 0.46 seconds\n",
      "2019-04-06 18:09:43,421 - link.src.py_scripts.process_line-9399 - INFO - Job finished, execution time 0.49 seconds\n",
      "2019-04-06 18:09:43,427 - link.src.py_scripts.process_line-9396 - INFO - Job finished, execution time 0.50 seconds\n",
      "2019-04-06 18:09:43,470 - link.src.py_scripts.process_line-9394 - INFO - Job finished, execution time 0.54 seconds\n",
      "2019-04-06 18:09:43,524 - process_pals.py - INFO - Combining results into single dict\n",
      "2019-04-06 18:09:43,525 - process_pals.py - INFO - Creating df\n",
      "2019-04-06 18:09:43,540 - process_pals.py - INFO - Writing df to RP3End.csv\n",
      "2019-04-06 18:09:43,586 - process_pals.py - INFO - Done! Execution time 0.84 seconds\n"
     ]
    }
   ],
   "source": [
    "# RP\n",
    "\n",
    "PATH = '../../data/processed_pseudogenes/RP_pals/'\n",
    "LINES = 'last'\n",
    "OMIT = ''\n",
    "OUTPUT_FILE = 'RP3End.csv'\n",
    "N_LINES = 0\n",
    "\n",
    "_ = begin_processing(\n",
    "    PATH,\n",
    "    LINES,\n",
    "    OMIT,\n",
    "    output_file=OUTPUT_FILE,\n",
    "    n_lines=N_LINES,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuf_alu_path = '../../data/Alu/NoPolyA/shuffled_last_50/'\n",
    "shuf_alu_files = os.listdir(shuf_alu_path)\n",
    "sequences = []\n",
    "for f_n in shuf_alu_files:\n",
    "    with open(os.path.join(shuf_alu_path, f_n), 'r') as file:\n",
    "        sequences.append(file.readlines()[0].strip().upper())\n",
    "sequences = np.unique(sequences)\n",
    "\n",
    "with open('alu_50_last_shuffled.csv', 'w') as file:\n",
    "    for seq in sequences:\n",
    "        file.write(seq)\n",
    "        file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "RP_path = '../../data/processed_pseudogenes/RP/'\n",
    "RP_files = os.listdir(RP_path)\n",
    "sequences = []\n",
    "for f_n in RP_files:\n",
    "    with open(os.path.join(RP_path, f_n), 'r') as file:\n",
    "        sequences.append(file.readlines()[1].strip().upper())\n",
    "sequences = np.unique(sequences)\n",
    "\n",
    "with open('RP_50_last_shuffled.csv', 'w') as file:\n",
    "    for seq in sequences:\n",
    "        file.write(seq)\n",
    "        file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dataframes(files):\n",
    "    dataframes = []\n",
    "    for filename in files:\n",
    "        dataframes.append(pd.read_csv(filename, sep=';'))\n",
    "    return pd.concat(dataframes)\n",
    "result_df = merge_dataframes(['AluS3UTR.csv', 'AluY3UTR.csv'])\n",
    "if result_df is not None:\n",
    "    result_df = result_df.drop(['Unnamed: 0'], axis=1)\n",
    "    result_df.to_csv('Alu3UTR.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
