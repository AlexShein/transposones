{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, precision_score, recall_score, precision_recall_curve, average_precision_score\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 17\n",
    "np.random.seed(17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trinucleotides(lst):\n",
    "    \"\"\"\n",
    "    '1234' -> ['123','234']\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    for i in range(len(lst) - 2):\n",
    "        res.append(lst[i]+lst[i + 1]+lst[i + 2])\n",
    "    return res\n",
    "\n",
    "\n",
    "def get_dinucleotides(lst):\n",
    "    \"\"\"\n",
    "    '123' -> ['12', '23']\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    for i in range(len(lst) - 1):\n",
    "        res.append(lst[i]+lst[i + 1])\n",
    "    return res\n",
    "\n",
    "def annotate_with_di_tri_nucleotides(lines):\n",
    "    annotated_rows = []\n",
    "    for line in lines:\n",
    "        row = {}\n",
    "        for di_n in get_dinucleotides(line)+get_trinucleotides(line):\n",
    "            row[di_n]=row.get(di_n,0)+1\n",
    "        annotated_rows.append(row)\n",
    "    return pd.DataFrame(annotated_rows).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True positive data\n",
    "l1_50_bp = []\n",
    "target_file = 'L1_50_last.txt'\n",
    "with open(target_file, 'r') as file:\n",
    "    for line in file:\n",
    "        l1_50_bp.append(line.strip())\n",
    "\n",
    "pseudogenes_50_bp = []\n",
    "target_file = 'pseudogenes_50_last.txt'\n",
    "with open(target_file, 'r') as file:\n",
    "    for line in file:\n",
    "        pseudogenes_50_bp.append(line.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(pseudogenes_50_bp) > len(l1_50_bp):\n",
    "    t_sequences_list = np.append(\n",
    "        np.random.choice(np.array(pseudogenes_50_bp), len(l1_50_bp), replace=False),\n",
    "        l1_50_bp\n",
    "    )\n",
    "else:\n",
    "    t_sequences_list = np.append(\n",
    "        np.random.choice(np.array(l1_50_bp), len(pseudogenes_50_bp), replace=False),\n",
    "        pseudogenes_50_bp\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True negative data\n",
    "l1_shuffled_50_bp = []\n",
    "target_file = 'L1_50_last_shuffled.txt'\n",
    "with open(target_file, 'r') as file:\n",
    "    for line in file:\n",
    "        l1_shuffled_50_bp.append(line.strip())\n",
    "\n",
    "pseudogenes_shuffled_50_bp = []\n",
    "target_file = 'KnownGene_50_last_shuffled.txt'\n",
    "with open(target_file, 'r') as file:\n",
    "    for line in file:\n",
    "        pseudogenes_shuffled_50_bp.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(pseudogenes_shuffled_50_bp) > len(l1_shuffled_50_bp):\n",
    "    f_sequences_list = np.append(\n",
    "        np.random.choice(np.array(pseudogenes_shuffled_50_bp), len(l1_shuffled_50_bp), replace=False),\n",
    "        l1_shuffled_50_bp\n",
    "    )\n",
    "else:\n",
    "    f_sequences_list = np.append(\n",
    "        np.random.choice(np.array(l1_shuffled_50_bp), len(pseudogenes_shuffled_50_bp), replace=False),\n",
    "        pseudogenes_shuffled_50_bp\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = len(f_sequences_list)/len(t_sequences_list); m = min(p,1/p)\n",
    "t_sequences_list = np.random.choice(t_sequences_list,round(len(t_sequences_list)*m), replace=False)\n",
    "f_sequences_list = np.random.choice(f_sequences_list, len(f_sequences_list), replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True positive data\n",
    "df_True = annotate_with_di_tri_nucleotides(t_sequences_list)\n",
    "# True negative data\n",
    "df_False = annotate_with_di_tri_nucleotides(f_sequences_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis & visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_True.shape[0] > df_False.shape[0]:\n",
    "    df_True_n = df_True.sample(df_False.shape[0], random_state=random_seed)\n",
    "    df_False_n = df_False\n",
    "else:\n",
    "    df_True_n = df_True\n",
    "    df_False_n = df_False.sample(df_True.shape[0], random_state=random_seed)\n",
    "    \n",
    "X = pd.concat([df_True_n, df_False_n], ignore_index=True)\n",
    "Y = pd.Series(np.append(np.full(df_True_n.shape[0], 1), \n",
    "                        np.full(df_False_n.shape[0], 0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_jobs=6, n_estimators=2000)\n",
    "folded_data = KFold(n_splits=5, random_state=random_seed, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tprs = []\n",
    "aucs, acc, rec, prec = [], [], [], []\n",
    "\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "i = 0\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "for k, (train, test) in enumerate(folded_data.split(X, Y)):\n",
    "    probas_ = rf.fit(X.iloc[train], Y.iloc[train]).predict_proba(X.iloc[test])\n",
    "    # Compute ROC curve and area the curve\n",
    "    fpr, tpr, thresholds = roc_curve(Y.iloc[test], probas_[:, 1])\n",
    "    tprs.append(np.interp(mean_fpr, fpr, tpr))\n",
    "    tprs[-1][0] = 0.0\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    Y_pred = rf.predict(X.iloc[test])\n",
    "    acc.append(accuracy_score(Y.iloc[test], Y_pred))\n",
    "    prec.append(precision_score(Y.iloc[test], Y_pred))\n",
    "    rec.append(recall_score(Y.iloc[test], Y_pred))\n",
    "    plt.plot(\n",
    "        fpr,\n",
    "        tpr,\n",
    "        lw=1,\n",
    "        alpha=0.3,\n",
    "        label='ROC fold %d (AUC = %0.2f)' % (k, roc_auc)\n",
    "    )\n",
    "\n",
    "plt.plot(\n",
    "    [0, 1],\n",
    "    [0, 1],\n",
    "    linestyle='--',\n",
    "    lw=2,\n",
    "    color='r',\n",
    "    label='Luck',\n",
    "    alpha=.8\n",
    ")\n",
    "fpr, tpr, thresholds = roc_curve(Y.iloc[test], probas_[:, 1])\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "         label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "         lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "plt.fill_between(\n",
    "    mean_fpr,\n",
    "    tprs_lower,\n",
    "    tprs_upper,\n",
    "    color='grey',\n",
    "    alpha=.2,\n",
    "    label=r'$\\pm$ 1 std. dev.'\n",
    ")\n",
    "\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic for transposon recognition')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions = []\n",
    "\n",
    "best_precision = {\"precision_score\": 0.0, \"precision\": None, \"recall\": None}\n",
    "\n",
    "for k, (train, test) in enumerate(folded_data.split(X, Y)):\n",
    "    probas_ = rf.fit(X.iloc[train], Y.iloc[train]).predict_proba(X.iloc[test])\n",
    "    precision, recall, _ = precision_recall_curve(Y.iloc[test], probas_[:, 1])\n",
    "    average_precision = average_precision_score(Y.iloc[test], probas_[:, 1])\n",
    "    if average_precision > best_precision[\"precision_score\"]:\n",
    "        best_precision[\"precision\"] = precision\n",
    "        best_precision[\"recall\"] = recall\n",
    "        best_precision[\"precision_score\"] = average_precision\n",
    "    precisions.append(average_precision)\n",
    "    plt.step(\n",
    "        recall,\n",
    "        precision,\n",
    "        alpha=0.5,\n",
    "        where='post',\n",
    "        label='Precision-recall fold {0:0.4f}'.format(average_precision)\n",
    "    )\n",
    "average_precision = sum(precisions)/len(precisions)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.05])\n",
    "plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(\n",
    "          average_precision))\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUC, Accuracy, Precision & Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mr = lambda x: np.round(np.mean(x), 4)\n",
    "mr(aucs), mr(acc), mr(prec), mr(rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_to_print = 10\n",
    "y_pos = range(N_to_print)\n",
    "fig, ax = plt.subplots()\n",
    "plt.figure(figsize=(10,7))\n",
    "\n",
    "feature_importance = rf.feature_importances_.round(4)\n",
    "feature_importance = zip(X.keys(), feature_importance)\n",
    "feature_importance = np.array(sorted(feature_importance, key=lambda x:x[1], reverse=True))\n",
    "\n",
    "ax.barh(y_pos, feature_importance[:N_to_print, 1].astype('float'), align='center', color='green')\n",
    "ax.set_yticks(np.arange(N_to_print))\n",
    "ax.set_yticklabels(feature_importance[:N_to_print, 0])\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlabel('Importance score')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = (rf.feature_importances_).round(4)\n",
    "feature_importance = zip(X.keys(), feature_importance)\n",
    "feature_importance = sorted(list(feature_importance), key=lambda x:x[1], reverse=True)\n",
    "fi = pd.DataFrame(feature_importance, columns=['Feature_name', 'Feature_importance'])\n",
    "fi.head(N_to_print)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further generalization analysis block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_FILE_SUBNAME_OBJECTS = \"L1_Pseudogenes_vs_Shuffle\" # \"True_vs_False\"\n",
    "CSV_FILE_SUBNAME_TYPE = \"50b.p._Stats\" # \"50b.p._Stats\" or \"Stem-loop_Stats\"\n",
    "CSV_FILE_SUBNAME = \"{0}__{1}\".format(CSV_FILE_SUBNAME_OBJECTS, CSV_FILE_SUBNAME_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"fpr\": mean_fpr, \"tpr\": mean_tpr}).to_csv(\"AUC__{0}.csv\".format(CSV_FILE_SUBNAME), index=False)\n",
    "pd.DataFrame({\"precision\": best_precision[\"precision\"],\n",
    "              \"recall\": best_precision[\"recall\"]}).to_csv(\"Precision-Recall__{0}.csv\".format(CSV_FILE_SUBNAME), index=False)\n",
    "pd.DataFrame(fi).to_csv(\"Feature_importance__{0}.csv\".format(CSV_FILE_SUBNAME), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
