{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, precision_score, recall_score, precision_recall_curve, average_precision_score\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 17\n",
    "np.random.seed(17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trinucleotides(lst):\n",
    "    \"\"\"\n",
    "    '1234' -> ['123','234']\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    for i in range(len(lst) - 2):\n",
    "        res.append(lst[i]+lst[i + 1]+lst[i + 2])\n",
    "    return res\n",
    "\n",
    "\n",
    "def get_dinucleotides(lst):\n",
    "    \"\"\"\n",
    "    '123' -> ['12', '23']\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    for i in range(len(lst) - 1):\n",
    "        res.append(lst[i]+lst[i + 1])\n",
    "    return res\n",
    "\n",
    "def annotate_with_di_tri_nucleotides(lines):\n",
    "    annotated_rows = []\n",
    "    for line in lines:\n",
    "        row = {}\n",
    "        for di_n in get_dinucleotides(line)+get_trinucleotides(line):\n",
    "            row[di_n]=row.get(di_n,0)+1\n",
    "        annotated_rows.append(row)\n",
    "    return pd.DataFrame(annotated_rows).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True positive data\n",
    "l1_50_bp = []\n",
    "target_file = 'L1_50_last.txt'\n",
    "with open(target_file, 'r') as file:\n",
    "    for line in file:\n",
    "        l1_50_bp.append(line.strip())\n",
    "\n",
    "knownGene_50_bp = []\n",
    "target_file = 'KnownGene_50_last.txt'\n",
    "with open(target_file, 'r') as file:\n",
    "    for line in file:\n",
    "        knownGene_50_bp.append(line.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(knownGene_50_bp) > len(l1_50_bp):\n",
    "    t_sequences_list = np.append(\n",
    "        np.random.choice(np.array(knownGene_50_bp), len(l1_50_bp), replace=False),\n",
    "        l1_50_bp\n",
    "    )\n",
    "else:\n",
    "    t_sequences_list = np.append(\n",
    "        np.random.choice(np.array(l1_50_bp), len(knownGene_50_bp), replace=False),\n",
    "        knownGene_50_bp\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True negative data\n",
    "l1_shuffled_50_bp = []\n",
    "target_file = 'L1_50_last_shuffled.txt'\n",
    "with open(target_file, 'r') as file:\n",
    "    for line in file:\n",
    "        l1_shuffled_50_bp.append(line.strip())\n",
    "\n",
    "knownGene_shuffled_50_bp = []\n",
    "target_file = 'KnownGene_50_last_shuffled.txt'\n",
    "with open(target_file, 'r') as file:\n",
    "    for line in file:\n",
    "        knownGene_shuffled_50_bp.append(line.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(knownGene_shuffled_50_bp) > len(l1_shuffled_50_bp):\n",
    "    f_sequences_list = np.append(\n",
    "        np.random.choice(np.array(knownGene_shuffled_50_bp), len(l1_shuffled_50_bp), replace=False),\n",
    "        l1_shuffled_50_bp\n",
    "    )\n",
    "else:\n",
    "    f_sequences_list = np.append(\n",
    "        np.random.choice(np.array(l1_shuffled_50_bp), len(knownGene_shuffled_50_bp), replace=False),\n",
    "        knownGene_shuffled_50_bp\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = len(f_sequences_list)/len(t_sequences_list); m = min(p,1/p)\n",
    "t_sequences_list = np.random.choice(t_sequences_list,round(len(t_sequences_list)*m), replace=False)\n",
    "f_sequences_list = np.random.choice(f_sequences_list, len(f_sequences_list), replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True positive data\n",
    "df_True = annotate_with_di_tri_nucleotides(t_sequences_list)\n",
    "# True negative data\n",
    "df_False = annotate_with_di_tri_nucleotides(f_sequences_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis & visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "if df_True.shape[0] > df_False.shape[0]:\n",
    "    df_True_n = df_True.sample(df_False.shape[0], random_state=random_seed)\n",
    "    df_False_n = df_False\n",
    "else:\n",
    "    df_True_n = df_True\n",
    "    df_False_n = df_False.sample(df_True.shape[0], random_state=random_seed)\n",
    "    \n",
    "X = pd.concat([df_True_n, df_False_n], ignore_index=True)\n",
    "Y = pd.Series(np.append(np.full(df_True_n.shape[0], 1), \n",
    "                        np.full(df_False_n.shape[0], 0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_jobs=6, n_estimators=2000)\n",
    "folded_data = KFold(n_splits=5, random_state=random_seed, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-14b9789dbc58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolded_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mprobas_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Compute ROC curve and area the curve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobas_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;31m# Validate or convert input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 573\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan)\u001b[0m\n\u001b[1;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x504 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tprs = []\n",
    "aucs, acc, rec, prec = [], [], [], []\n",
    "\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "i = 0\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "for k, (train, test) in enumerate(folded_data.split(X, Y)):\n",
    "    probas_ = rf.fit(X.iloc[train], Y.iloc[train]).predict_proba(X.iloc[test])\n",
    "    # Compute ROC curve and area the curve\n",
    "    fpr, tpr, thresholds = roc_curve(Y.iloc[test], probas_[:, 1])\n",
    "    tprs.append(np.interp(mean_fpr, fpr, tpr))\n",
    "    tprs[-1][0] = 0.0\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    Y_pred = rf.predict(X.iloc[test])\n",
    "    acc.append(accuracy_score(Y.iloc[test], Y_pred))\n",
    "    prec.append(precision_score(Y.iloc[test], Y_pred))\n",
    "    rec.append(recall_score(Y.iloc[test], Y_pred))\n",
    "    plt.plot(\n",
    "        fpr,\n",
    "        tpr,\n",
    "        lw=1,\n",
    "        alpha=0.3,\n",
    "        label='ROC fold %d (AUC = %0.2f)' % (k, roc_auc)\n",
    "    )\n",
    "\n",
    "plt.plot(\n",
    "    [0, 1],\n",
    "    [0, 1],\n",
    "    linestyle='--',\n",
    "    lw=2,\n",
    "    color='r',\n",
    "    label='Luck',\n",
    "    alpha=.8\n",
    ")\n",
    "fpr, tpr, thresholds = roc_curve(Y.iloc[test], probas_[:, 1])\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "         label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "         lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "plt.fill_between(\n",
    "    mean_fpr,\n",
    "    tprs_lower,\n",
    "    tprs_upper,\n",
    "    color='grey',\n",
    "    alpha=.2,\n",
    "    label=r'$\\pm$ 1 std. dev.'\n",
    ")\n",
    "\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic for transposon recognition')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions = []\n",
    "\n",
    "best_precision = {\"precision_score\": 0.0, \"precision\": None, \"recall\": None}\n",
    "\n",
    "for k, (train, test) in enumerate(folded_data.split(X, Y)):\n",
    "    probas_ = rf.fit(X.iloc[train], Y.iloc[train]).predict_proba(X.iloc[test])\n",
    "    precision, recall, _ = precision_recall_curve(Y.iloc[test], probas_[:, 1])\n",
    "    average_precision = average_precision_score(Y.iloc[test], probas_[:, 1])\n",
    "    if average_precision > best_precision[\"precision_score\"]:\n",
    "        best_precision[\"precision\"] = precision\n",
    "        best_precision[\"recall\"] = recall\n",
    "        best_precision[\"precision_score\"] = average_precision\n",
    "    precisions.append(average_precision)\n",
    "    plt.step(\n",
    "        recall,\n",
    "        precision,\n",
    "        alpha=0.5,\n",
    "        where='post',\n",
    "        label='Precision-recall fold {0:0.4f}'.format(average_precision)\n",
    "    )\n",
    "average_precision = sum(precisions)/len(precisions)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.05])\n",
    "plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(\n",
    "          average_precision))\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUC, Accuracy, Precision & Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mr = lambda x: np.round(np.mean(x), 4)\n",
    "mr(aucs), mr(acc), mr(prec), mr(rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_to_print = 10\n",
    "y_pos = range(N_to_print)\n",
    "fig, ax = plt.subplots()\n",
    "plt.figure(figsize=(10,7))\n",
    "\n",
    "feature_importance = rf.feature_importances_.round(4)\n",
    "feature_importance = zip(X.keys(), feature_importance)\n",
    "feature_importance = np.array(sorted(feature_importance, key=lambda x:x[1], reverse=True))\n",
    "\n",
    "ax.barh(y_pos, feature_importance[:N_to_print, 1].astype('float'), align='center', color='green')\n",
    "ax.set_yticks(np.arange(N_to_print))\n",
    "ax.set_yticklabels(feature_importance[:N_to_print, 0])\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlabel('Importance score')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = (rf.feature_importances_).round(4)\n",
    "feature_importance = zip(X.keys(), feature_importance)\n",
    "feature_importance = sorted(list(feature_importance), key=lambda x:x[1], reverse=True)\n",
    "fi = pd.DataFrame(feature_importance, columns=['Feature_name', 'Feature_importance'])\n",
    "fi.head(N_to_print)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further generalization analysis block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_FILE_SUBNAME_OBJECTS = \"L1_KnownGene_vs_Shuffle\" # \"True_vs_False\"\n",
    "CSV_FILE_SUBNAME_TYPE = \"50b.p._Stats\" # \"50b.p._Stats\" or \"Stem-loop_Stats\"\n",
    "CSV_FILE_SUBNAME = \"{0}__{1}\".format(CSV_FILE_SUBNAME_OBJECTS, CSV_FILE_SUBNAME_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"fpr\": mean_fpr, \"tpr\": mean_tpr}).to_csv(\"AUC__{0}.csv\".format(CSV_FILE_SUBNAME), index=False)\n",
    "pd.DataFrame({\"precision\": best_precision[\"precision\"],\n",
    "              \"recall\": best_precision[\"recall\"]}).to_csv(\"Precision-Recall__{0}.csv\".format(CSV_FILE_SUBNAME), index=False)\n",
    "pd.DataFrame(fi).to_csv(\"Feature_importance__{0}.csv\".format(CSV_FILE_SUBNAME), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
